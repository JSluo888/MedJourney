#!/usr/bin/env python3
"""
AIé™ªä¼´å¯¹è¯è½®æ¬¡é™åˆ¶ä¿®å¤è„šæœ¬

é—®é¢˜åˆ†æï¼š
1. max_memory_length è®¾ç½®ä¸º10ï¼Œé™åˆ¶äº†å¯¹è¯å†å²è®°å¿†
2. force_threshold_ms è®¾ç½®ä¸º30ç§’ï¼Œå¯èƒ½è¿‡çŸ­
3. Turn Detection å†³ç­–é€»è¾‘å¯èƒ½è¿‡äºä¸¥æ ¼

è§£å†³æ–¹æ¡ˆï¼š
1. å¢åŠ  max_memory_length åˆ°50è½®
2. å¢åŠ  force_threshold_ms åˆ°60ç§’æˆ–ç¦ç”¨
3. ä¼˜åŒ– Turn Detection é…ç½®
4. å¢åŠ  max_tokens ä»¥æ”¯æŒæ›´é•¿å›å¤
"""

import os
import json
import re
from pathlib import Path

def fix_conversation_limits():
    """ä¿®å¤AIé™ªä¼´å¯¹è¯çš„è½®æ¬¡é™åˆ¶é—®é¢˜"""
    
    print("ğŸ”§ å¼€å§‹ä¿®å¤AIé™ªä¼´å¯¹è¯è½®æ¬¡é™åˆ¶...")
    
    # 1. ä¿®å¤ Turn Detection é…ç½®
    config_file = "ten-framework/ai_agents/agents/ten_packages/extension/ten_turn_detection/config.py"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°†å¼ºåˆ¶èŠå¤©è¶…æ—¶ä»30ç§’å¢åŠ åˆ°60ç§’
        content = re.sub(
            r'force_threshold_ms: int = \d+',
            'force_threshold_ms: int = 60000  # 60ç§’è¶…æ—¶',
            content
        )
        
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… å·²ä¿®å¤ {config_file} - å¼ºåˆ¶èŠå¤©è¶…æ—¶å¢åŠ åˆ°60ç§’")
    
    # 2. ä¿®å¤æ‰€æœ‰ property.json æ–‡ä»¶ä¸­çš„å¯¹è¯é™åˆ¶
    property_files = [
        "ten-framework/ai_agents/agents/examples/demo/property.json",
        "ten-framework/ai_agents/agents/examples/huggingface/property.json",
        "ten-framework/ai_agents/agents/examples/default/property.json",
        "ten-framework/ai_agents/agents/examples/experimental/property.json"
    ]
    
    for prop_file in property_files:
        if os.path.exists(prop_file):
            with open(prop_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°† max_memory_length ä»10å¢åŠ åˆ°50
            content = re.sub(
                r'"max_memory_length": 10',
                '"max_memory_length": 50',
                content
            )
            
            # å°† max_tokens ä»512å¢åŠ åˆ°1024
            content = re.sub(
                r'"max_tokens": 512',
                '"max_tokens": 1024',
                content
            )
            
            # å°† temperature ä»0.1å¢åŠ åˆ°0.7ï¼Œä½¿å¯¹è¯æ›´è‡ªç„¶
            content = re.sub(
                r'"temperature": 0\.1',
                '"temperature": 0.7',
                content
            )
            
            with open(prop_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… å·²ä¿®å¤ {prop_file} - å¯¹è¯é™åˆ¶å‚æ•°å·²ä¼˜åŒ–")
    
    # 3. åˆ›å»ºä¸“é—¨ç”¨äºAIé™ªä¼´çš„ä¼˜åŒ–é…ç½®
    create_optimized_companion_config()
    
    # 4. ä¿®å¤ OpenAI ChatGPT æ‰©å±•çš„é»˜è®¤é…ç½®
    fix_openai_extension_defaults()
    
    print("ğŸ‰ AIé™ªä¼´å¯¹è¯è½®æ¬¡é™åˆ¶ä¿®å¤å®Œæˆï¼")

def create_optimized_companion_config():
    """åˆ›å»ºä¸“é—¨ç”¨äºAIé™ªä¼´çš„ä¼˜åŒ–é…ç½®"""
    
    optimized_config = {
        "ten": {
            "log": {
                "level": 3
            },
            "predefined_graphs": [
                {
                    "name": "ai_companion_optimized",
                    "auto_start": true,
                    "graph": {
                        "nodes": [
                            {
                                "type": "extension",
                                "name": "agora_rtc",
                                "addon": "agora_rtc",
                                "extension_group": "default",
                                "property": {
                                    "app_id": "${env:AGORA_APP_ID}",
                                    "token": "<agora_token>",
                                    "channel": "ai_companion",
                                    "stream_id": 1234,
                                    "remote_stream_id": 123,
                                    "subscribe_audio": true,
                                    "publish_audio": true,
                                    "publish_data": true,
                                    "enable_agora_asr": true,
                                    "agora_asr_vendor_name": "microsoft",
                                    "agora_asr_language": "zh-CN",
                                    "agora_asr_vendor_key": "${env:AZURE_STT_KEY}",
                                    "agora_asr_vendor_region": "${env:AZURE_STT_REGION}",
                                    "agora_asr_session_control_file_path": "session_control.conf"
                                }
                            },
                            {
                                "type": "extension",
                                "name": "llm",
                                "addon": "openai_chatgpt_python",
                                "extension_group": "chatgpt",
                                "property": {
                                    "api_key": "${env:OPENAI_API_KEY}",
                                    "base_url": "${env:OPENAI_API_BASE}",
                                    "frequency_penalty": 0.9,
                                    "presence_penalty": 0.9,
                                    "greeting": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIé™ªä¼´åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿ",
                                    "max_memory_length": 50,  # å¢åŠ åˆ°50è½®
                                    "max_tokens": 1024,       # å¢åŠ åˆ°1024
                                    "model": "${env:OPENAI_MODEL}",
                                    "temperature": 0.7,       # å¢åŠ åˆ›é€ æ€§
                                    "prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€æ¸©æš–ã€æœ‰è€å¿ƒçš„AIåŒ»ç–—é™ªä¼´åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…æ‚£è€…æä¾›é™ªä¼´å’Œæ”¯æŒã€‚\n\nè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n1. ä½¿ç”¨æ¸©å’Œã€äº²åˆ‡ã€æ˜“æ‡‚çš„ä¸­æ–‡è¯­è¨€\n2. ä¿æŒç§¯æä¹è§‚çš„æ€åº¦\n3. æä¾›æƒ…æ„Ÿæ”¯æŒå’Œé™ªä¼´\n4. é¿å…å¤æ‚çš„åŒ»å­¦æœ¯è¯­\n5. é¼“åŠ±æ‚£è€…åˆ†äº«æ„Ÿå—å’Œå›å¿†\n6. å¦‚æ¶‰åŠå…·ä½“åŒ»ç–—é—®é¢˜ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ\n7. å›å¤åº”è¯¥ç®€æ´æ˜äº†ï¼Œä¾¿äºç†è§£\n8. ä¸»åŠ¨å¼•å¯¼å¯¹è¯ï¼Œé¿å…æ²‰é»˜\n9. è®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œå»ºç«‹è¿ç»­æ€§\n10. åœ¨é€‚å½“æ—¶æœºä¸»åŠ¨è¯¢é—®æ‚£è€…çš„æ„Ÿå—å’Œéœ€æ±‚\n\nè¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”è¦äº²åˆ‡è‡ªç„¶ï¼Œåƒæœ‹å‹ä¸€æ ·èŠå¤©ã€‚",
                                    "proxy_url": "${env:OPENAI_PROXY_URL}"
                                }
                            },
                            {
                                "type": "extension",
                                "name": "tts",
                                "addon": "azure_tts",
                                "extension_group": "tts",
                                "property": {
                                    "azure_subscription_key": "${env:AZURE_TTS_KEY}",
                                    "azure_subscription_region": "${env:AZURE_TTS_REGION}",
                                    "azure_synthesis_voice_name": "zh-CN-XiaoxiaoNeural"
                                }
                            },
                            {
                                "type": "extension",
                                "name": "turn_detector",
                                "addon": "ten_turn_detection",
                                "extension_group": "default",
                                "property": {
                                    "force_threshold_ms": 60000,  # 60ç§’è¶…æ—¶
                                    "temperature": 0.3,
                                    "top_p": 0.3
                                }
                            },
                            {
                                "type": "extension",
                                "name": "interrupt_detector",
                                "addon": "interrupt_detector_python",
                                "extension_group": "default",
                                "property": {}
                            },
                            {
                                "type": "extension",
                                "name": "message_collector",
                                "addon": "message_collector",
                                "extension_group": "transcriber",
                                "property": {}
                            },
                            {
                                "type": "extension",
                                "name": "adapter",
                                "extension_group": "default",
                                "addon": "data_adapter_python"
                            }
                        ],
                        "connections": [
                            {
                                "extension": "agora_rtc",
                                "cmd": [
                                    {
                                        "name": "on_user_joined",
                                        "dest": [{"extension": "llm"}]
                                    },
                                    {
                                        "name": "on_user_left",
                                        "dest": [{"extension": "llm"}]
                                    }
                                ],
                                "data": [
                                    {
                                        "name": "text_data",
                                        "dest": [{"extension": "adapter"}]
                                    }
                                ]
                            },
                            {
                                "extension": "adapter",
                                "data": [
                                    {
                                        "name": "text_data",
                                        "dest": [
                                            {"extension": "turn_detector"},
                                            {"extension": "llm"}
                                        ]
                                    }
                                ]
                            },
                            {
                                "extension": "turn_detector",
                                "data": [
                                    {
                                        "name": "turn_decision",
                                        "dest": [{"extension": "llm"}]
                                    }
                                ]
                            },
                            {
                                "extension": "llm",
                                "data": [
                                    {
                                        "name": "text_data",
                                        "dest": [
                                            {"extension": "tts"},
                                            {"extension": "message_collector"}
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                }
            ]
        }
    }
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®ç›®å½•
    config_dir = "ten-framework/ai_agents/agents/examples/ai_companion_optimized"
    os.makedirs(config_dir, exist_ok=True)
    
    # ä¿å­˜ä¼˜åŒ–é…ç½®
    config_file = f"{config_dir}/property.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(optimized_config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²åˆ›å»ºä¼˜åŒ–é…ç½®: {config_file}")

def fix_openai_extension_defaults():
    """ä¿®å¤OpenAI ChatGPTæ‰©å±•çš„é»˜è®¤é…ç½®"""
    
    openai_config_file = "ten-framework/ai_agents/agents/ten_packages/extension/openai_chatgpt_python/openai.py"
    if os.path.exists(openai_config_file):
        with open(openai_config_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä¿®æ”¹é»˜è®¤çš„ max_memory_length
        content = re.sub(
            r'max_memory_length: int = 10',
            'max_memory_length: int = 50',
            content
        )
        
        # ä¿®æ”¹é»˜è®¤çš„ max_tokens
        content = re.sub(
            r'max_tokens: int = 512',
            'max_tokens: int = 1024',
            content
        )
        
        # ä¿®æ”¹é»˜è®¤çš„ temperature
        content = re.sub(
            r'temperature: float = 0\.1',
            'temperature: float = 0.7',
            content
        )
        
        # ä¿®æ”¹é»˜è®¤çš„ prompt ä¸ºä¸­æ–‡åŒ»ç–—é™ªä¼´
        medical_prompt = '''prompt: str = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€æ¸©æš–ã€æœ‰è€å¿ƒçš„AIåŒ»ç–—é™ªä¼´åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…æ‚£è€…æä¾›é™ªä¼´å’Œæ”¯æŒã€‚\\n\\nè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\\n1. ä½¿ç”¨æ¸©å’Œã€äº²åˆ‡ã€æ˜“æ‡‚çš„ä¸­æ–‡è¯­è¨€\\n2. ä¿æŒç§¯æä¹è§‚çš„æ€åº¦\\n3. æä¾›æƒ…æ„Ÿæ”¯æŒå’Œé™ªä¼´\\n4. é¿å…å¤æ‚çš„åŒ»å­¦æœ¯è¯­\\n5. é¼“åŠ±æ‚£è€…åˆ†äº«æ„Ÿå—å’Œå›å¿†\\n6. å¦‚æ¶‰åŠå…·ä½“åŒ»ç–—é—®é¢˜ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ\\n7. å›å¤åº”è¯¥ç®€æ´æ˜äº†ï¼Œä¾¿äºç†è§£\\n8. ä¸»åŠ¨å¼•å¯¼å¯¹è¯ï¼Œé¿å…æ²‰é»˜\\n9. è®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œå»ºç«‹è¿ç»­æ€§\\n10. åœ¨é€‚å½“æ—¶æœºä¸»åŠ¨è¯¢é—®æ‚£è€…çš„æ„Ÿå—å’Œéœ€æ±‚\\n\\nè¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”è¦äº²åˆ‡è‡ªç„¶ï¼Œåƒæœ‹å‹ä¸€æ ·èŠå¤©ã€‚"
    )'''
        
        content = re.sub(
            r'prompt: str = \([\s\S]*?\)',
            medical_prompt,
            content
        )
        
        with open(openai_config_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… å·²ä¿®å¤ {openai_config_file} - é»˜è®¤é…ç½®å·²ä¼˜åŒ–")

def create_conversation_monitor():
    """åˆ›å»ºå¯¹è¯ç›‘æ§è„šæœ¬"""
    
    monitor_script = """#!/usr/bin/env python3
import asyncio
import logging
from datetime import datetime

class ConversationMonitor:
    def __init__(self):
        self.turn_count = 0
        self.last_turn_time = None
        self.conversation_start_time = None
        self.max_turns = 50  # æ–°çš„æœ€å¤§è½®æ¬¡é™åˆ¶
        
    def on_turn_start(self, turn_id: int):
        self.turn_count = turn_id
        self.last_turn_time = datetime.now()
        if not self.conversation_start_time:
            self.conversation_start_time = self.last_turn_time
        
        print(f"ğŸ”„ å¯¹è¯è½®æ¬¡ {turn_id} å¼€å§‹ - æ€»è½®æ¬¡: {self.turn_count}")
        
        # æ£€æŸ¥æ˜¯å¦æ¥è¿‘é™åˆ¶
        if turn_id >= self.max_turns - 5:
            print(f"âš ï¸  è­¦å‘Š: å·²è¾¾åˆ°ç¬¬ {turn_id} è½®å¯¹è¯ï¼Œæ¥è¿‘æœ€å¤§é™åˆ¶ {self.max_turns}")
    
    def on_turn_end(self, turn_id: int, decision: str):
        duration = datetime.now() - self.last_turn_time if self.last_turn_time else None
        print(f"âœ… å¯¹è¯è½®æ¬¡ {turn_id} ç»“æŸ - å†³ç­–: {decision} - è€—æ—¶: {duration}")
        
        # æ£€æŸ¥å¼‚å¸¸æƒ…å†µ
        if decision == "Wait" and turn_id >= 3:
            print(f"ğŸš¨ å¼‚å¸¸: ç¬¬ {turn_id} è½®å¯¹è¯è¢«è®¾ç½®ä¸ºç­‰å¾…çŠ¶æ€ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
    
    def on_conversation_end(self, reason: str):
        total_duration = datetime.now() - self.conversation_start_time if self.conversation_start_time else None
        print(f"ğŸ”š å¯¹è¯ç»“æŸ - åŸå› : {reason} - æ€»è½®æ¬¡: {self.turn_count} - æ€»è€—æ—¶: {total_duration}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    monitor = ConversationMonitor()
    print("ğŸ¯ AIé™ªä¼´å¯¹è¯ç›‘æ§å™¨å·²å¯åŠ¨")
    print("ğŸ’¡ ä¼˜åŒ–åçš„é…ç½®:")
    print("   - max_memory_length: 50è½®")
    print("   - max_tokens: 1024")
    print("   - temperature: 0.7")
    print("   - force_threshold_ms: 60000ms")
    print("   - ä¸­æ–‡åŒ»ç–—é™ªä¼´ä¸“ç”¨prompt")
"""
    
    with open("conversation_monitor.py", 'w', encoding='utf-8') as f:
        f.write(monitor_script)
    
    print("âœ… å·²åˆ›å»ºå¯¹è¯ç›‘æ§è„šæœ¬: conversation_monitor.py")

if __name__ == "__main__":
    fix_conversation_limits()
    create_conversation_monitor()
    
    print("\nğŸ“‹ ä¿®å¤æ€»ç»“:")
    print("1. âœ… å¢åŠ  max_memory_length ä»10åˆ°50è½®")
    print("2. âœ… å¢åŠ  max_tokens ä»512åˆ°1024")
    print("3. âœ… å¢åŠ  temperature ä»0.1åˆ°0.7")
    print("4. âœ… å¢åŠ  force_threshold_ms ä»30ç§’åˆ°60ç§’")
    print("5. âœ… ä¼˜åŒ–ä¸­æ–‡åŒ»ç–—é™ªä¼´prompt")
    print("6. âœ… åˆ›å»ºä¸“é—¨çš„AIé™ªä¼´ä¼˜åŒ–é…ç½®")
    print("\nğŸš€ ç°åœ¨AIé™ªä¼´å¯¹è¯åº”è¯¥èƒ½å¤ŸæŒç»­æ›´é•¿æ—¶é—´äº†ï¼") 